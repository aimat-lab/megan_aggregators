import os
import random
import typing as t
from collections import defaultdict

import numpy as np
from rich import print as pprint
from sklearn.metrics import pairwise_distances
from sklearn.metrics import accuracy_score
from pycomex.functional.experiment import Experiment
from pycomex.utils import folder_path, file_namespace
from visual_graph_datasets.config import Config
from visual_graph_datasets.web import ensure_dataset
from visual_graph_datasets.data import VisualGraphDatasetReader
from graph_attention_student.torch.megan import Megan
from megan_global_explanations.main import extract_concepts
from megan_global_explanations.main import generate_concept_prototypes
from megan_global_explanations.main import generate_concept_hypotheses
from megan_global_explanations.prototype.molecules import mutate_remove_atom
from megan_global_explanations.prototype.molecules import mutate_remove_bond
from megan_global_explanations.visualization import create_concept_cluster_report
from megan_global_explanations.visualization import concept_umap_visualization
from megan_global_explanations.data import ConceptWriter
from megan_global_explanations.gpt import query_gpt

from megan_aggregators.utils import EXPERIMENTS_PATH
from megan_aggregators.utils import ASSETS_PATH

# == SOURCE PARAMETERS ==
# These parameters define the data sources which are needed for the concept extraction. This for 
# example includes the dataset that is to be used for the concept extraction and the model that is
# to be used for the concept extraction.

# :param VISUAL_GRAPH_DATASET:
#       The path to the visual graph dataset that is to be used for the concept extraction. This may
#       either be a string path to a visual graph dataset folder on the local system or a string
#       identifier for a visual graph dataset that is available on the remote file share.
VISUAL_GRAPH_DATASET: str = os.path.join(EXPERIMENTS_PATH, 'assets', 'cache', 'aggregators_binary_protonated', 'all')
# :param DATASET_TYPE:
#       The type of the dataset that is to be used for the concept extraction. This may either be
#       "classification" or "regression". For the aggregation dataset this will simply always be 
#       classification
DATASET_TYPE: str = 'classification'
# :param MODEL_PATH:
#       The path to the model that is to be used for the concept extraction. This has to be an absolute 
#       string path to an existing checkpoint file that represents a stored model.
MODEL_PATH: str = os.path.join(EXPERIMENTS_PATH, 'assets', 'models', 'aggregators_binary_protonated_2.ckpt')
MODEL_PATH: str = os.path.join(ASSETS_PATH, 'models', 'model_7.ckpt')

# == CONCEPT PARAMETERS ==
# These parameters define the behavior of the concept extraction procedure.

# :param FIDELITY_THRESHOLD:
#       The threshold for the fidelity of the concepts that are to be extracted. This threshold determines the 
#       minimum fidelity which an explanation is supposed to have to still be considered a meaningful explanation.
#       During the concept clustering, all explanations associated with a fidelity below this threshold will be 
#       discarded.
FIDELITY_THRESHOLD: float = 0.5
# :param MIN_CLUSTER_SIZE:
#       This is the minimum number of elements a concept cluster has to have to be considered a valid cluster.
#       This is a parameter of the HDSCAN clustering algorithm that is used for the concept clustering.
MIN_CLUSTER_SIZE: int = 10
# :param MIN_SAMPLES:
#       This is the minimum number of samples that are needed to form a cluster in the HDSCAN clustering algorithm.
#       This is a parameter of the HDSCAN clustering algorithm that is used for the concept clustering.
#       This parameter determines how conservative the clustering algorithm is. The higher this value, the fewer 
#       clusters there will be.
MIN_SAMPLES: int = 10
# :param CHANNEL_INFOS:
#       This dictionary can be used to add additional information about the explanation channels that
#       are used in this experiment. The integer keys of the dict are the indices of the channels
#       and the values are dictionaries that contain the information about the channel with that index.
CHANNEL_INFOS: t.Dict[int, dict] = {
    0: {'name': 'aggregator', 'color': '#FF7B2F'},
    1: {'name': 'non-aggregator', 'color': '#3EFFAF'},
}
# :param OPTIMIZE_PROTOTYPE:
#       This boolean flag determines whether the concept prototypes are supposed to be optimized or not.
#       If this flag is set to True, then the concept prototypes will be optimized using a genetic algorithm
#       to find the most representative graph for each concept cluster.
OPTIMIZE_PROTOTYPE: bool = False
# :param GENERATE_HYPOTHESIS:
#       This boolean flag determines whether to generate the concept hypotheses for each concept or not. 
#       The concept hypothesis is optionally generated by passing the prototype pattern of each concept 
#       to a GPT language model along with the evidence about it's average contribution to the prediction 
#       outcome. The language model is then prompted to generate a natural language hypothesis about the 
#       underlying domain rules that would support the given structure property relationship.
GENERATE_HYPOTHESIS: bool = False
# :param OPENAI_KEY:
#       This is a string key that is needed to access the OpenAI API. This key is needed to generate the
#       concept hypotheses. If this key is not set, then the concept hypotheses will not be generated.
OPENAI_KEY: t.Optional[str] = os.getenv('OPENAI_KEY', None)

# == EXPERIMENT PARAMETERS ==

__DEBUG__ = True

experiment = Experiment(
    base_path=folder_path(__file__),
    namespace=file_namespace(__file__),
    glob=globals()
)

@experiment.hook('get_dataset_path')
def get_dataset_path(e: Experiment) -> str:
    """
    This hook is responsible for returning the path to the visual graph dataset that is to be used
    for the concept clustering. This may either be an absolute string path to a visual graph dataset
    folder on the local system. Otherwise this may also be a valid string identifier for a vgd in
    which case it will be downloaded from the remote file share instead.
    """
    if os.path.exists(e.VISUAL_GRAPH_DATASET):
        dataset_path = e.VISUAL_GRAPH_DATASET
        
    else:
        dataset_path = ensure_dataset(
            dataset_name=e.VISUAL_GRAPH_DATASET,
            config=Config().load(),
            logger=e.logger,
        )
        
    return dataset_path


@experiment.hook('load_dataset', replace=False)
def load_dataset(e: Experiment,
                 path: str,
                 ) -> dict:
    """
    This hook takes a local path to a (visual graph) dataset as the only argument and is then 
    responsibe for loading and returning that dataset as a index_data_map.
    
    Additionally, this function has to set up the experiment values "node_dim", "edge_dim" and "out_dim"
    based on the dataset that has been loaded.
    
    This default implementation uses the default VisualGraphDatasetReader to load the dataset from the disk.
    """
    reader = VisualGraphDatasetReader(
        path=path,
        logger=e.logger,
        log_step=1000,
    )
    index_data_map = reader.read()
    processing = reader.read_process().processing
    
    example_graph = list(index_data_map.values())[0]['metadata']['graph']
    e['node_dim'] = example_graph['node_attributes'].shape[1]
    e['edge_dim'] = example_graph['edge_attributes'].shape[1]
    e['out_dim'] = example_graph['graph_labels'].shape[0]
    e.log(f'loaded dataset with {e["node_dim"]} node features and {e["edge_dim"]} edge features')
    
    return index_data_map, processing

@experiment.hook('load_model')
def load_model(e: Experiment) -> Megan:
    """
    This hooks is supposed to load the Megan model from the disk representation and return it.
    
    This base implementation just loads a Megan model from the path that is defined in the
    MODEL_PATH experiment value.
    """
    model = Megan.load(e.MODEL_PATH)
    return model


@experiment
def experiment(e: Experiment):
    
    e.log('starting experiment for concept extraction...')
    
    if not e.OPENAI_KEY:
        e.log(' * WARNING: No OpenAI key is set. Concept hypotheses will not be generated.')
        
    # ~ loading the dataset
    e.log('loading dataset...')
    dataset_path = e.apply_hook('get_dataset_path')
    index_data_map, processing = e.apply_hook(
        'load_dataset', 
        path=dataset_path
    )
    indices = list(index_data_map.keys())
    graphs = [index_data_map[index]['metadata']['graph'] for index in indices]
    e.log(f'loaded dataset with {len(index_data_map)} elements')
    
    e.log(f'extending graph dict with graph representation...')
    for index, data in index_data_map.items():
        graph = data['metadata']['graph']
        #graph['graph_repr'] = data['metadata']['graph_repr']
    
    # ~ loading the model
    e.log('loading model...')
    model = e.apply_hook('load_model')
    num_channels = model.num_channels
    e.log(f'loaded model of type {model.__class__.__name__} with {num_channels} channels')
    
    # ~ concept extraction
    # The concept extraction is wrapped in the megan_global_explanations package and mainly consists of 
    # two parts. In the first part, the actual concepts are extracted as dense clusters in the model's latent 
    # space using the "extract_concepts" function.
    # In the second part the concepts are then visualized and analyzed using the 
    # "create_concept_cluster_report" function, which will create a PDF file in which all the concepts are 
    # listed and visualized.
    
    e.log('starting concept extraction...')
    concepts: t.List[dict] = extract_concepts(
        model=model,
        index_data_map=index_data_map,
        processing=processing,
        fidelity_threshold=e.FIDELITY_THRESHOLD,
        min_cluster_size=e.MIN_CLUSTER_SIZE,
        min_samples=e.MIN_SAMPLES,
        cluster_selection_method='leaf',
        channel_infos=e.CHANNEL_INFOS,
        dataset_type=e.DATASET_TYPE,
        sort_similarity=False,
        logger=e.logger
    )
    e.log(f'extracted {len(concepts)} concepts')
    
    # ~ UMAP visualization
    # The UMAP visualization is a visualization of the concepts in the latent space of the model. This visualization
    # is supposed to give an overview of how the concepts are distributed in the latent space and how they relate to
    # each other.
    
    e.log('creating UMAP visualization...')
    fig, mappers = concept_umap_visualization(
        concepts=concepts,
        graphs=graphs,
        channel_infos=e.CHANNEL_INFOS,
        fidelity_threshold=e.FIDELITY_THRESHOLD,
        min_dist=0.0,
        num_neighbors=100,
        base_figsize=10,
        repulsion_strength=5,
        logger=e.logger,
    )
    fig_path = os.path.join(e.path, 'umap_concepts.pdf')
    fig.savefig(fig_path)
    fig_path = os.path.join(e.path, 'umap_concepts.png')
    fig.savefig(fig_path)
    
    for info, mapper in zip(e.CHANNEL_INFOS.values(), mappers):
        info['mapper'] = mapper
        
    fig, mappers = concept_umap_visualization(
        concepts=concepts,
        graphs=graphs,
        channel_infos=e.CHANNEL_INFOS,
        fidelity_threshold=e.FIDELITY_THRESHOLD,
        min_dist=0.0,
        num_neighbors=150,
        base_figsize=15,
        repulsion_strength=1.0,
        logger=e.logger,
        plot_concepts=False,
    )
    fig_path = os.path.join(e.path, 'umap_concepts_raw.png')
    fig.savefig(fig_path)
    
    # ~ creating the linear model
    # In this section we want to create a linear classification model from these concepts and see how well that model 
    # performs on the original task.
    # For this we find the closest concept for all of the elements in the dataset and then use the contribution value of 
    # those concepts to decide on the clusters
    
    e.log('creating linear classification model from concepts...')
    
    # In this first step here we need to iterate over all the elements of the dataset and determine the closest cluster 
    # and from that closest concept cluster we can get the linear contribution.
    channel_concept_map = {
        channel_index: [concept for concept in concepts if concept['channel_index'] == channel_index]
        for channel_index in range(num_channels)
    }
        
    for index, data in index_data_map.items():
        graph = data['metadata']['graph']
        graph['graph_concepts'] = np.zeros(shape=(num_channels, ))
        graph['graph_contributions'] = np.zeros(shape=(num_channels, ))
        
        for channel_index in range(num_channels):
            graph_embedding = graph['graph_embeddings'][:, channel_index]
            distances = pairwise_distances(
                [graph_embedding], 
                [concept['centroid'] for concept in channel_concept_map[channel_index]], 
                metric='manhattan',
            )
            index = np.argmin(distances[0])
            concept = channel_concept_map[channel_index][index]

            graph['graph_concepts'][channel_index] = concept['index']
            graph['graph_contributions'][channel_index] = concept['contribution']
    
    # Now that we have calculated the corresponding closest concepts and therefore also the contributions of the
    # concepts to the graph, we can now decide on the class based on those contribution values.
    labels_pred = [np.argmax(graph['graph_contributions']) for graph in graphs]
    labels_true = [np.argmax(graph['graph_labels']) for graph in graphs]
    
    acc_value = accuracy_score(labels_true, labels_pred)
    e.log(f'linear classfication accuracy: {acc_value:.2f}')
    
    # ~ concept prototypes
    # concept prototypes are a construct that can be generated in addition to the concept information, which is 
    # supposed to help with recognizing what the essential pattern of the cluster is. The "generate_concept_prototypes"
    # function does this with an optimization procedure that will generate one such concept graph for every 
    # concept of an already existing concepts list. Since it needs to compute an optimization procedure for every
    # concept, this can be quite time consuming.
    # The information about the prototype graph will then automatically be added to the concept dict in-place. 
    # The concept report visualization can then automatically detect if a concept contains the information about a 
    # prototype and will visualize that prototype in the report.
    if e.OPTIMIZE_PROTOTYPE:
        
        e.log('starting concept prototype optimization...')
        concepts = generate_concept_prototypes(
            concepts=concepts,
            model=model,
            index_data_map=index_data_map,
            processing=processing,
            mutate_funcs=[
                lambda element: mutate_remove_atom(element, processing=processing),
                lambda element: mutate_remove_bond(element, processing=processing),
            ],
            initial_strategy='centroid',
            population_size=500,
            num_epochs=20,
            logger=e.logger,
            path=e.path,
        )
        
    # ~ concept hypotheses
    # concept hypotheses are optional natural language explanations that offer possible explanations as to *why* 
    # a certain concept may be important for the prediction outcome. This is done by passing the prototype graph
    # of the concept to a language model along with the information about the average contribution of the members
    # of that concept to the prediction outcome. The language model is then prompted to generate a natural language
    # hypothesis about the underlying domain rules that would support the given structure property relationship.
    if e.GENERATE_HYPOTHESIS:
        
        def contribution_func(index, contribution):
            if contribution > 0:
                impact = 'MODERATE'
            if contribution > 2:
                impact = 'HIGH'
                
            if index == 0:
                channel = 'AGGREGATION'
            if index == 1:
                channel = 'NON-AGGREGATION'
                
            return f'{impact} towards {channel}'
        
        e.log('starting to generate concept hypotheses...')
        concepts = generate_concept_hypotheses(
            concepts=concepts,
            task_name='Molecular Aggregation',
            task_description='Molecular Aggregation - A molecules tendency to form aggregates / clusters in solution',
            openai_key=e.OPENAI_KEY,
            contribution_func=contribution_func,
            logger=e.logger,
        )
        
    # The raw information about this concept clustering will potentially also be important 
    # later on, which is why we want to save it to the disk.
    e.log(f'saving the concepts to disk...')
    concepts_path = os.path.join(e.path, 'concepts')
    os.mkdir(concepts_path)
    pprint(concepts[0])
    writer = ConceptWriter(
        path=concepts_path,
        processing=processing,
        model=model,
        logger=e.logger,
        # With this flag we specify that we want to export the elements directly instead of 
        # just implicitly by index.
        write_elements=True,
    )
    writer.write(concepts)
    
    # ~ concept clustering report
    # The concept clusters in the raw form are not very useful for the user, which is why we want to create a
    # report that visualizes the concepts in a human readable way. This report will be saved as a PDF file.
    
    e.log('starting concept visualization...')
    cache_path = os.path.join(e.path, 'cache')
    os.mkdir(cache_path)
    
    report_path = os.path.join(e.path, 'concept_report.pdf')
    create_concept_cluster_report(
        cluster_data_list=concepts,
        path=report_path,
        dataset_type=e.DATASET_TYPE,
        logger=e.logger,
        cache_path=cache_path,
        num_examples=16,
        examples_type='centroid',
    )
    
    # ~ exporting concept positive and negative SMILES
    # This section exports the concept clusters as separate .smiles files to the disk. These files simply 
    # contain the SMILES representations of the members---one SMILES per line. This can be used for the 
    # online tool SMARTS.plus to generate a SMARTS pattern for each cluster.
    # https://smarts.plus/
    
    e.log('exporting concept members as .SMILES files...')
    folder_path = os.path.join(e.path, 'concepts_smiles')
    os.mkdir(folder_path)
    for concept in concepts:
        concept_graphs = concept['graphs']
        file_path = os.path.join(folder_path, f'concept_{concept["index"]}.smiles')
        with open(file_path, mode='w') as file:
            file.write('\n'.join([str(graph['graph_repr']) for graph in concept_graphs]))
                
    negative_graphs = random.sample(graphs, k=2000)
    file_path = os.path.join(folder_path, 'negative.smiles')
    with open(file_path, mode='w') as file:
        file.write('\n'.join([str(graph['graph_repr']) for graph in negative_graphs]))
        
    # ~ reduced concept clustering report
    # We will create another concept clustering report that only contains the most important concepts 
    # measured by the average (fidelity) contribution of their members.
    # To do this we simply delete all the concepts that are not among those with the highest contribution
    
    # First of all we create a dictionary, whose keys are the explanation channel indices and the values 
    # are the concepts that belong to that channel.
    channel_concept_map = defaultdict(list)
    for concept in concepts:
        concept_channel = concept['channel_index']
        channel_concept_map[concept_channel].append(concept)
    
    # Now we can order those by the contribution of that concept and then take the top 5 concepts 
    # of each channel and create a new concept clustering report only for that subset.
    concepts_reduced = []
    for channel_index, concepts in channel_concept_map.items():
        concepts = sorted(concepts, key=lambda concept: abs(concept['contribution']), reverse=True)
        concepts_reduced.extend(concepts[:5])
        
    report_path = os.path.join(e.path, 'concept_report_reduced.pdf')
    create_concept_cluster_report(
        cluster_data_list=concepts_reduced,
        path=report_path,
        dataset_type=e.DATASET_TYPE,
        logger=e.logger,
        cache_path=cache_path,
        num_examples=16,
        examples_type='centroid',
    )
    

experiment.run_if_main()