import os
import pathlib
import typing as t

from pycomex.functional.experiment import Experiment
from pycomex.utils import folder_path, file_namespace
from megan_aggregators.utils import EXPERIMENTS_PATH, ASSETS_PATH

# == SOURCE PARAMETERS ==
# These parameters define the data sources which are needed for the concept extraction. This for 
# example includes the dataset that is to be used for the concept extraction and the model that is
# to be used for the concept extraction.

# :param VISUAL_GRAPH_DATASET:
#       The path to the visual graph dataset that is to be used for the concept extraction. This may
#       either be a string path to a visual graph dataset folder on the local system or a string
#       identifier for a visual graph dataset that is available on the remote file share.
VISUAL_GRAPH_DATASET: str = os.path.join(EXPERIMENTS_PATH, 'assets', 'cache', 'aggregators_combined', 'all')
#VISUAL_GRAPH_DATASET: str = os.path.join(EXPERIMENTS_PATH, 'assets', 'cache', 'aggregators_binary_protonated', 'all')
# :param DATASET_TYPE:
#       The type of the dataset that is to be used for the concept extraction. This may either be
#       "classification" or "regression". For the aggregation dataset this will simply always be 
#       classification
DATASET_TYPE: str = 'classification'
# :param MODEL_PATH:
#       The path to the model that is to be used for the concept extraction. This has to be an absolute 
#       string path to an existing checkpoint file that represents a stored model.
#MODEL_PATH: str = os.path.join(EXPERIMENTS_PATH, 'results', 'vgd_torch_chunked_megan__antibiotics', '006_with_contrastive', 'model_best.ckpt')
MODEL_PATH: str = os.path.join(EXPERIMENTS_PATH, 'results', 'vgd_torch_chunked_megan__aggregators_binary', 'candidate_3', 'model.ckpt')

# == CONCEPT PARAMETERS ==
# These parameters define the behavior of the concept extraction procedure.

# :param FIDELITY_THRESHOLD:
#       The threshold for the fidelity of the concepts that are to be extracted. This threshold determines the 
#       minimum fidelity which an explanation is supposed to have to still be considered a meaningful explanation.
#       During the concept clustering, all explanations associated with a fidelity below this threshold will be 
#       discarded.
FIDELITY_THRESHOLD: float = 0.5
# :param MIN_CLUSTER_SIZE:
#       This is the minimum number of elements a concept cluster has to have to be considered a valid cluster.
#       This is a parameter of the HDSCAN clustering algorithm that is used for the concept clustering.
MIN_CLUSTER_SIZE: int = 10
# :param MIN_SAMPLES:
#       This is the minimum number of samples that are needed to form a cluster in the HDSCAN clustering algorithm.
#       This is a parameter of the HDSCAN clustering algorithm that is used for the concept clustering.
#       This parameter determines how conservative the clustering algorithm is. The higher this value, the fewer 
#       clusters there will be.
MIN_SAMPLES: int = 3
#MIN_SAMPLES: int = 15
# :param CHANNEL_INFOS:
#       This dictionary can be used to add additional information about the explanation channels that
#       are used in this experiment. The integer keys of the dict are the indices of the channels
#       and the values are dictionaries that contain the information about the channel with that index.
CHANNEL_INFOS: t.Dict[int, dict] = {
    0: {'name': 'non-aggregator', 'color': '#3EFFAF'},
    1: {'name': 'aggregator', 'color': '#FF7B2F'},
}
# :param OPTIMIZE_PROTOTYPE:
#       This boolean flag determines whether the concept prototypes are supposed to be optimized or not.
#       If this flag is set to True, then the concept prototypes will be optimized using a genetic algorithm
#       to find the most representative graph for each concept cluster.
OPTIMIZE_PROTOTYPE: bool = False
# :param GENERATE_HYPOTHESIS:
#       This boolean flag determines whether to generate the concept hypotheses for each concept or not. 
#       The concept hypothesis is optionally generated by passing the prototype pattern of each concept 
#       to a GPT language model along with the evidence about it's average contribution to the prediction 
#       outcome. The language model is then prompted to generate a natural language hypothesis about the 
#       underlying domain rules that would support the given structure property relationship.
GENERATE_HYPOTHESIS: bool = False
# :param OPENAI_KEY:
#       This is a string key that is needed to access the OpenAI API. This key is needed to generate the
#       concept hypotheses. If this key is not set, then the concept hypotheses will not be generated.
OPENAI_KEY: t.Optional[str] = os.getenv('OPENAI_KEY', None)

experiment = Experiment.extend(
    'concept_extraction.py',
    base_path=folder_path(__file__),
    namespace=file_namespace(__file__),
    glob=globals(),
)

experiment.run_if_main()